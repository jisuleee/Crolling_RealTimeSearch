{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 크롤링(스크레이핑, 파싱)에 사용할 라이브러리를 import 한다.\n",
    "라이브러리 설치  \n",
    "pip install requests => 크롤링할 사이트에 접속해서 html 문서를 읽어온다.  \n",
    "pip install beautifulsoup4 => requests를 사용해 읽어온 html 문서에서 필요한 데이터를 읽어온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# requests 모듈의 get() 함수를 사용해 크롤링할 웹 사이트에 접속해서 html 문서를 읽어온다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "request = requests.get(\"http://www.naver.com/\")\n",
    "print(request)\n",
    "# print(request) # <Response [200]> => 타겟 사이트에 정상적으로 접속했다.\n",
    "# naver 사이트에서 읽어온 문서 내용 중 html 태그(text)만 얻어온다.\n",
    "\n",
    "html = request.text\n",
    "#print(html)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BeautifulSoup 모듈의 BeautifulSoup() 함수를 사용해 html 문서를 파싱할 준비를 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "현재 시간 2019-08-13 22:30:42.250804의 실시간 검색어\n",
      " 1위 -> 키토제닉 식단\n",
      " 2위 -> 장윤정\n",
      " 3위 -> 전영록\n",
      " 4위 -> 이덕화 나이\n",
      " 5위 -> 김세연\n",
      " 6위 -> 꾼\n",
      " 7위 -> 남윤국 변호사\n",
      " 8위 -> 덕화다방\n",
      " 9위 -> 가수전영록나이\n",
      "10위 -> 솜혜인\n",
      "11위 -> 이지안\n",
      "12위 -> 이병헌동생 이은희\n",
      "13위 -> 류준열 혜리\n",
      "14위 -> 미스코리아 김세연\n",
      "15위 -> 김창환\n",
      "16위 -> 권민중\n",
      "17위 -> 메리츠 펫보험\n",
      "18위 -> 비디오스타\n",
      "19위 -> 주아민\n",
      "20위 -> 아사\n",
      "21위 -> 키토제닉 식단\n",
      "22위 -> 장윤정\n",
      "23위 -> 전영록\n",
      "24위 -> 이덕화 나이\n",
      "25위 -> 김세연\n",
      "26위 -> 꾼\n",
      "27위 -> 남윤국 변호사\n",
      "28위 -> 덕화다방\n",
      "29위 -> 가수전영록나이\n",
      "30위 -> 솜혜인\n",
      "31위 -> 이지안\n",
      "32위 -> 이병헌동생 이은희\n",
      "33위 -> 류준열 혜리\n",
      "34위 -> 미스코리아 김세연\n",
      "35위 -> 김창환\n",
      "36위 -> 권민중\n",
      "37위 -> 메리츠 펫보험\n",
      "38위 -> 비디오스타\n",
      "39위 -> 주아민\n",
      "40위 -> 아사\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(html,'html.parser')\n",
    "issues = soup.findAll('span',{'class':'ah_k'})\n",
    "\n",
    "#BeautifulSoup() 함수를 사용해 파싱할 준비가된 객체에서 필요한 데이터만 얻어온다.\n",
    "# 네이버 실시간 검색어는 순위가 class 속성의 값이 'ah_r'인 span 태그 내부에 들어있고 검색어는 class 속성의 값이 'ah_k'인 span 태그 내부에 들어있다.\n",
    "# findAll('태그이름', {'속성이름' : '속성값'})\n",
    "from datetime import datetime as dt \n",
    "now = dt.now()\n",
    "\n",
    "print(\"현재 시간 {}의 실시간 검색어\".format(now))\n",
    "\n",
    "for i in range(len(marks)) :\n",
    "    print(\"{0:2d}위 -> {1}\".format(i+1,issues[i].text))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Daum 실시간 검색어 크롤링하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "  1위 => 전영록\n",
      "  2위 => 김세연\n",
      "  3위 => 밀정\n",
      "  4위 => 사노라면\n",
      "  5위 => 김원중\n",
      "  6위 => 강백호\n",
      "  7위 => 김창환\n",
      "  8위 => 이지안\n",
      "  9위 => 차별금지법\n",
      " 10위 => 류준열\n",
      " 11위 => 전영록\n",
      " 12위 => 밀정\n",
      " 13위 => 김원중\n",
      " 14위 => 김창환\n",
      " 15위 => 차별금지법\n",
      " 16위 => 전영록\n",
      " 17위 => 김세연\n",
      " 18위 => 밀정\n",
      " 19위 => 사노라면\n",
      " 20위 => 김원중\n",
      " 21위 => 강백호\n",
      " 22위 => 김창환\n",
      " 23위 => 이지안\n",
      " 24위 => 차별금지법\n",
      " 25위 => 류준열\n"
     ]
    }
   ],
   "source": [
    "request = requests.get(\"http://daum.net/\")\n",
    "print(request)\n",
    "\n",
    "html = request.text\n",
    "#print(html)\n",
    "\n",
    "soup = BeautifulSoup(html,'html')\n",
    "issues = soup.findAll('a',{'class':'link_issue'})\n",
    "\n",
    "#print(issues)\n",
    "\n",
    "for i in range(0,len(issues),2) :\n",
    "    print(\"{0:3d}위 => {1}\".format(i//2+1,issues[i].text))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
